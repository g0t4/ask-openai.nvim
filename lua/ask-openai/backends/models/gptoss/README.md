The best way to make sure I understand this model is to parse the harmony format myself.
For example, I just recently discovered that it supports CoT tool use. And that I need to keep
the thinking tokens until a `final` message is generated. Even across turns (tool calls).

Anyways, I want to build my own streaming parser and really grasp the possible interactions.

Then I am free to use mine or go back to using jinja templates w/ llama.cpp (llama-server)


